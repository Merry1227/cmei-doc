
#X2Vec整体认识
https://blog.csdn.net/sinat_26917383/article/details/69666596
https://github.com/MaxwellRebo/awesome-2vec 

#词向量 Word2Vec 也叫word embeddings 
  * 如何在巨大的词典中表示某个词
  * 用什么样的方式表示词，才能更方便的描述词与词之间的关系？

  参考：https://www.cnblogs.com/pinard/p/7160330.html  
   https://www.cnblogs.com/iloveai/p/gensim_tutorial2.html  
   
  Embedding其实是将词或者句子/文档向量化
  word2vec是google在2013年推出的一个NLP工具，它的特点是将所有的词向量化，这样词与词之间就可以定量的去度量他们之间的关系，挖掘词之间的联系。
  非常清楚的介绍了word2vec的前世今生: http://www.cnblogs.com/iloveai/p/word2vec.html    
  
##CBOW

##Skip-gram  

#Doc2Vec
https://www.cnblogs.com/iloveai/p/gensim_tutorial2.html

#FastText
http://www.52nlp.cn/fasttext
https://blog.csdn.net/sinat_26917383/article/details/54850933




    
    
    
    